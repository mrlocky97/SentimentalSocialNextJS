/**
 * Script de Entrenamiento y Evaluaci√≥n Naive Bayes
 * Entrena el modelo y eval√∫a su rendimiento vs sistema actual
 */

import { NaiveBayesSentimentModel } from '../experimental/naive-bayes.model';
import { SentimentAnalysisService } from '../services/sentiment-analysis.service';
import { getBalancedDataset, getDatasetStatistics, splitDataset } from '../data/training-dataset';

interface EvaluationMetrics {
  accuracy: number;
  precision: { positive: number; negative: number; neutral: number; macro: number };
  recall: { positive: number; negative: number; neutral: number; macro: number };
  f1Score: { positive: number; negative: number; neutral: number; macro: number };
  confusionMatrix: number[][];
  avgProcessingTime: number;
}

class NaiveBayesEvaluation {
  private naiveBayesModel: NaiveBayesSentimentModel;
  private ruleBasedModel: SentimentAnalysisService;

  constructor() {
    this.naiveBayesModel = new NaiveBayesSentimentModel({
      smoothingFactor: 1.0,
      minWordLength: 2,
      maxVocabularySize: 5000,
      enableBigrams: false,
      enableTfIdf: false
    });
    this.ruleBasedModel = new SentimentAnalysisService();
  }

  /**
   * Ejecutar evaluaci√≥n completa
   */
  async runCompleteEvaluation(): Promise<void> {
    console.log('üöÄ INICIANDO EVALUACI√ìN NAIVE BAYES VS RULE-BASED');
    console.log('================================================\n');

    // Mostrar estad√≠sticas del dataset
    const datasetStats = getDatasetStatistics();
    console.log('');

    // Dividir dataset
    console.log('üìä Dividiendo dataset en entrenamiento y prueba...');
    const { train, test } = splitDataset(0.2);
    console.log(`üéØ Entrenamiento: ${train.length} textos`);
    console.log(`üß™ Prueba: ${test.length} textos\n`);

    // Entrenar Naive Bayes
    console.log('üß† ENTRENANDO MODELO NAIVE BAYES');
    console.log('================================');
    await this.naiveBayesModel.train(train);
    console.log('');

    // Evaluar ambos modelos
    console.log('üìà EVALUANDO MODELOS');
    console.log('===================');
    
    console.log('üîç Evaluando Naive Bayes...');
    const nbMetrics = await this.evaluateModel(this.naiveBayesModel, test, 'naive-bayes');
    console.log('');

    console.log('üîç Evaluando Rule-Based...');
    const rbMetrics = await this.evaluateModel(this.ruleBasedModel, test, 'rule-based');
    console.log('');

    // Comparar resultados
    this.compareModels(nbMetrics, rbMetrics);

    // Casos de prueba espec√≠ficos
    console.log('\nüéØ CASOS DE PRUEBA ESPEC√çFICOS');
    console.log('=============================');
    await this.testSpecificCases();

    console.log('\n‚úÖ EVALUACI√ìN COMPLETADA');
  }

  /**
   * Evaluar un modelo espec√≠fico
   */
  private async evaluateModel(model: any, testData: any[], modelName: string): Promise<EvaluationMetrics> {
    const predictions: string[] = [];
    const actuals: string[] = [];
    const processingTimes: number[] = [];

    for (const sample of testData) {
      const startTime = Date.now();
      
      let prediction: string;
      if (modelName === 'naive-bayes') {
        const result = await model.predict(sample.text);
        prediction = this.normalizeSentimentLabel(result.label);
      } else {
        const result = await model.analyze(sample.text);
        prediction = this.normalizeSentimentLabel(result.sentiment.label);
      }
      
      const endTime = Date.now();
      processingTimes.push(endTime - startTime);
      
      predictions.push(prediction);
      actuals.push(this.normalizeSentimentLabel(sample.sentiment));
    }

    return this.calculateMetrics(predictions, actuals, processingTimes, modelName);
  }

  /**
   * Normalizar etiquetas para comparaci√≥n
   */
  private normalizeSentimentLabel(label: string): string {
    if (label === 'very_positive' || label === 'positive') return 'positive';
    if (label === 'very_negative' || label === 'negative') return 'negative';
    return 'neutral';
  }

  /**
   * Calcular m√©tricas de evaluaci√≥n
   */
  private calculateMetrics(predictions: string[], actuals: string[], times: number[], modelName: string): EvaluationMetrics {
    const labels = ['positive', 'negative', 'neutral'];
    const confusionMatrix = this.buildConfusionMatrix(predictions, actuals, labels);
    
    // Calcular m√©tricas por clase
    const precision: any = {};
    const recall: any = {};
    const f1Score: any = {};

    for (let i = 0; i < labels.length; i++) {
      const label = labels[i];
      const tp = confusionMatrix[i][i];
      const fp = confusionMatrix.reduce((sum, row, idx) => idx !== i ? sum + row[i] : sum, 0);
      const fn = confusionMatrix[i].reduce((sum, val, idx) => idx !== i ? sum + val : sum, 0);

      precision[label] = tp === 0 ? 0 : tp / (tp + fp);
      recall[label] = tp === 0 ? 0 : tp / (tp + fn);
      f1Score[label] = (precision[label] + recall[label]) === 0 ? 0 : 
        2 * (precision[label] * recall[label]) / (precision[label] + recall[label]);
    }

    // M√©tricas macro
    const macroPrecision = (Object.values(precision) as number[]).reduce((a, b) => a + b, 0) / 3;
    const macroRecall = (Object.values(recall) as number[]).reduce((a, b) => a + b, 0) / 3;
    const macroF1 = (Object.values(f1Score) as number[]).reduce((a, b) => a + b, 0) / 3;

    // Accuracy
    const accuracy = predictions.reduce((correct, pred, idx) => 
      pred === actuals[idx] ? correct + 1 : correct, 0) / predictions.length;

    const avgProcessingTime = times.reduce((a, b) => a + b, 0) / times.length;

    // Imprimir resultados
    this.printMetrics(modelName, {
      accuracy,
      precision: { ...precision, macro: macroPrecision },
      recall: { ...recall, macro: macroRecall },
      f1Score: { ...f1Score, macro: macroF1 },
      confusionMatrix,
      avgProcessingTime
    });

    return {
      accuracy,
      precision: { ...precision, macro: macroPrecision },
      recall: { ...recall, macro: macroRecall },
      f1Score: { ...f1Score, macro: macroF1 },
      confusionMatrix,
      avgProcessingTime
    };
  }

  /**
   * Construir matriz de confusi√≥n
   */
  private buildConfusionMatrix(predictions: string[], actuals: string[], labels: string[]): number[][] {
    const matrix = labels.map(() => new Array(labels.length).fill(0));
    
    for (let i = 0; i < predictions.length; i++) {
      const predIdx = labels.indexOf(predictions[i]);
      const actualIdx = labels.indexOf(actuals[i]);
      if (predIdx !== -1 && actualIdx !== -1) {
        matrix[actualIdx][predIdx]++;
      }
    }
    
    return matrix;
  }

  /**
   * Imprimir m√©tricas del modelo
   */
  private printMetrics(modelName: string, metrics: EvaluationMetrics): void {
    console.log(`üìä M√âTRICAS - ${modelName.toUpperCase()}`);
    console.log('‚îÄ'.repeat(40));
    console.log(`üéØ Accuracy: ${(metrics.accuracy * 100).toFixed(2)}%`);
    console.log(`‚ö° Tiempo promedio: ${metrics.avgProcessingTime.toFixed(2)}ms`);
    console.log('');
    console.log('üìà Precision por clase:');
    console.log(`  ‚úÖ Positive: ${(metrics.precision.positive * 100).toFixed(1)}%`);
    console.log(`  ‚ùå Negative: ${(metrics.precision.negative * 100).toFixed(1)}%`);
    console.log(`  ‚ö™ Neutral:  ${(metrics.precision.neutral * 100).toFixed(1)}%`);
    console.log(`  üìä Macro avg: ${(metrics.precision.macro * 100).toFixed(1)}%`);
    console.log('');
    console.log('üìà Recall por clase:');
    console.log(`  ‚úÖ Positive: ${(metrics.recall.positive * 100).toFixed(1)}%`);
    console.log(`  ‚ùå Negative: ${(metrics.recall.negative * 100).toFixed(1)}%`);
    console.log(`  ‚ö™ Neutral:  ${(metrics.recall.neutral * 100).toFixed(1)}%`);
    console.log(`  üìä Macro avg: ${(metrics.recall.macro * 100).toFixed(1)}%`);
    console.log('');
    console.log('üìà F1-Score por clase:');
    console.log(`  ‚úÖ Positive: ${(metrics.f1Score.positive * 100).toFixed(1)}%`);
    console.log(`  ‚ùå Negative: ${(metrics.f1Score.negative * 100).toFixed(1)}%`);
    console.log(`  ‚ö™ Neutral:  ${(metrics.f1Score.neutral * 100).toFixed(1)}%`);
    console.log(`  üìä Macro avg: ${(metrics.f1Score.macro * 100).toFixed(1)}%`);
  }

  /**
   * Comparar ambos modelos
   */
  private compareModels(nbMetrics: EvaluationMetrics, rbMetrics: EvaluationMetrics): void {
    console.log('üèÜ COMPARACI√ìN DE MODELOS');
    console.log('========================');
    
    const accuracyDiff = nbMetrics.accuracy - rbMetrics.accuracy;
    const speedDiff = rbMetrics.avgProcessingTime - nbMetrics.avgProcessingTime;
    const f1Diff = nbMetrics.f1Score.macro - rbMetrics.f1Score.macro;

    console.log(`üìä Accuracy:`);
    console.log(`  üß† Naive Bayes: ${(nbMetrics.accuracy * 100).toFixed(2)}%`);
    console.log(`  üìè Rule-Based:  ${(rbMetrics.accuracy * 100).toFixed(2)}%`);
    console.log(`  ${accuracyDiff > 0 ? 'üìà' : 'üìâ'} Diferencia: ${(accuracyDiff * 100).toFixed(2)}% ${accuracyDiff > 0 ? 'mejor' : 'peor'} Naive Bayes`);
    console.log('');

    console.log(`‚ö° Velocidad:`);
    console.log(`  üß† Naive Bayes: ${nbMetrics.avgProcessingTime.toFixed(2)}ms`);
    console.log(`  üìè Rule-Based:  ${rbMetrics.avgProcessingTime.toFixed(2)}ms`);
    console.log(`  ${speedDiff > 0 ? 'üêå' : '‚ö°'} Diferencia: ${Math.abs(speedDiff).toFixed(2)}ms ${speedDiff > 0 ? 'm√°s lento' : 'm√°s r√°pido'} Naive Bayes`);
    console.log('');

    console.log(`üìà F1-Score Macro:`);
    console.log(`  üß† Naive Bayes: ${(nbMetrics.f1Score.macro * 100).toFixed(2)}%`);
    console.log(`  üìè Rule-Based:  ${(rbMetrics.f1Score.macro * 100).toFixed(2)}%`);
    console.log(`  ${f1Diff > 0 ? 'üìà' : 'üìâ'} Diferencia: ${(f1Diff * 100).toFixed(2)}% ${f1Diff > 0 ? 'mejor' : 'peor'} Naive Bayes`);

    console.log('\nüéØ RECOMENDACI√ìN:');
    if (accuracyDiff > 0.05) {
      console.log('‚úÖ Naive Bayes muestra mejora significativa - RECOMENDADO para producci√≥n');
    } else if (accuracyDiff > 0.01) {
      console.log('ü§î Naive Bayes muestra mejora leve - Considera implementaci√≥n h√≠brida');
    } else {
      console.log('‚öñÔ∏è  Rendimiento similar - Eval√∫a otros factores (velocidad, mantenimiento)');
    }
  }

  /**
   * Probar casos espec√≠ficos
   */
  private async testSpecificCases(): Promise<void> {
    const testCases = [
      "Este producto es absolutamente incre√≠ble, lo recomiendo totalmente",
      "Terrible servicio, nunca m√°s compro aqu√≠",
      "El producto funciona bien, nada extraordinario",
      "Amazing quality! Best purchase ever made",
      "Worst experience, completely disappointed",
      "It's okay, does what it's supposed to do",
      "Aunque es caro, la calidad lo justifica",
      "Good product but delivery was delayed"
    ];

    console.log('Comparando predicciones en casos espec√≠ficos:\n');

    for (const text of testCases) {
      console.log(`üìù "${text.substring(0, 50)}..."`);
      
      // Naive Bayes
      const nbResult = await this.naiveBayesModel.predict(text);
      console.log(`  üß† Naive Bayes: ${nbResult.label} (confianza: ${(nbResult.confidence * 100).toFixed(1)}%)`);
      
      // Rule-Based
      const rbResult = await this.ruleBasedModel.analyze(text);
      console.log(`  üìè Rule-Based:  ${rbResult.sentiment.label} (confianza: ${(rbResult.sentiment.confidence * 100).toFixed(1)}%)`);
      
      console.log('');
    }
  }
}

// Ejecutar evaluaci√≥n
async function runEvaluation() {
  try {
    const evaluation = new NaiveBayesEvaluation();
    await evaluation.runCompleteEvaluation();
  } catch (error) {
    console.error('‚ùå Error en evaluaci√≥n:', error);
  }
}

// Ejecutar si es llamado directamente
if (require.main === module) {
  runEvaluation();
}

export { NaiveBayesEvaluation };
